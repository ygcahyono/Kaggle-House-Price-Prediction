{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31780e5a",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048f5ba6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.573130Z",
     "start_time": "2023-01-15T14:14:44.064169Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import calendar\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a675a04b",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa9ea7e",
   "metadata": {},
   "source": [
    "### Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baeb3b44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.584757Z",
     "start_time": "2023-01-15T14:14:45.574510Z"
    }
   },
   "outputs": [],
   "source": [
    "def X_preprocessing(df):\n",
    "    \n",
    "    # checking resposne variable\n",
    "    if 'SalePrice' not in df:\n",
    "        column_interval_dup = column_interval.copy()\n",
    "        column_interval_dup.remove('SalePrice')\n",
    "        \n",
    "    # drop useless column \"id\"\n",
    "    df = df.drop('Id', axis=1)\n",
    "    \n",
    "    df_nominal = df[column_nominal].copy()\n",
    "    df_interval = df[column_interval_dup].copy()\n",
    "\n",
    "    # preprocessing on interval dataframe\n",
    "    ## simple null value imputation: interval to 0\n",
    "    ## concat to the actual table\n",
    "    df_interval = df_interval.fillna(0)\n",
    "    df = df.drop(column_interval_dup, axis=1)\n",
    "    df = pd.concat([df, df_interval], axis=1)\n",
    "\n",
    "    # binary data convesion\n",
    "    df['CentralAir'] = df[column_binary]['CentralAir'].apply(lambda x: 1 if x == 'Y' else 0)\n",
    "\n",
    "    # preprocessing on nonimal dataframe\n",
    "    ## simple null value imputation: categorical to NaN\n",
    "    df_nominal = df_nominal.drop(col_major_missing, axis = 1)\n",
    "    df_nominal = df_nominal.fillna(nominal_mode)\n",
    "    \n",
    "\n",
    "    ## convert MSSubClass value to string\n",
    "    df_nominal['MSSubClass'] = df_nominal['MSSubClass'].astype('string')\n",
    "    df_nominal['MSSubClass'] = df_nominal['MSSubClass'].apply(lambda x: 'MSSC_'+x)\n",
    "\n",
    "    ## all set, convert all the categorical variable to dummies variables\n",
    "    df_nominal = pd.get_dummies(df_nominal)\n",
    "\n",
    "    ## concat to the actual table\n",
    "    df = df.drop(column_nominal, axis=1)\n",
    "    df = pd.concat([df, df_nominal], axis=1)\n",
    "\n",
    "    # preprocessing on time dataframe\n",
    "    ## time approach-renovation: comparing to the year built\n",
    "    ## time approach-soldyear: comparing to the year built\n",
    "    df['YearRemodAdd'] = df[column_time]['YearRemodAdd'] - df[column_time]['YearBuilt'] \n",
    "    df['YrSold'] = df[column_time]['YrSold'] - df[column_time]['YearBuilt']\n",
    "\n",
    "    ## time approach-built: comparing to the oldest listing on the market\n",
    "    df_yrbuilt_min = df[column_time]['YearBuilt'].min()\n",
    "    df['YearBuilt'] = df[column_time]['YearBuilt'].apply(lambda x: x - df_yrbuilt_min)\n",
    "\n",
    "    ## time apprach-soldmonth: to dummies variable\n",
    "    df['MoSold'] = df['MoSold'].apply(lambda x: 'sold_'+calendar.month_name[x])\n",
    "    df_dum_months = pd.get_dummies(df['MoSold'])\n",
    "    df = df.drop(['MoSold'], axis=1)\n",
    "\n",
    "    df = pd.concat([df,df_dum_months], axis=1)\n",
    "\n",
    "    if 'SalePrice' in df:\n",
    "    # final to split between dependent variable to resposne\n",
    "        X = df.drop('SalePrice', axis=1)\n",
    "        y = df['SalePrice']\n",
    "\n",
    "    else:\n",
    "        print('This is test dataset return only X...')\n",
    "        X = df.copy()\n",
    "        y = None\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7dda3dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.589621Z",
     "start_time": "2023-01-15T14:14:45.587057Z"
    }
   },
   "outputs": [],
   "source": [
    "def z_score_scaling(X_df, mean, stdev):\n",
    "    '''\n",
    "    This function converts the normal data after its pass preprocessing to z-score scalling\n",
    "    input: x df, mean, and stdev\n",
    "    output: x df (scalled)\n",
    "    '''\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b3f241",
   "metadata": {},
   "source": [
    "## Import data(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "013d4a53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.619466Z",
     "start_time": "2023-01-15T14:14:45.592876Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('data/train.csv')\n",
    "df_cols_process = pd.read_csv('data/column_types_and_process_imputation.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5df13964",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7587ca",
   "metadata": {},
   "source": [
    "-> Numerical - Categorical (two general groups) <- \n",
    "\n",
    "- Useless (unique identifier usually useless)\n",
    "- Nominal (as named or categorical)\n",
    "- Binary (either 1/0)\n",
    "- Ordinal (Ordinal)\n",
    "- Count (Integer number starting from 0 exclude negative number)\n",
    "- Time (consiting seasonal and date)\n",
    "- Interval (Examples include percentages, temperatures, and income.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b66fe1d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.626201Z",
     "start_time": "2023-01-15T14:14:45.620588Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cols_process['data types'] = df_cols_process['data types'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83d0ea97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:45.634619Z",
     "start_time": "2023-01-15T14:14:45.627246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['useless', 'nominal', 'interval', 'ordinal', 'time', 'binary'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cols_process['data types'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4859b79f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:46.484759Z",
     "start_time": "2023-01-15T14:14:46.464255Z"
    }
   },
   "outputs": [],
   "source": [
    "column_interval = list(df_cols_process[df_cols_process['data types'] == 'interval']['column']) # no need processing\n",
    "column_nominal = list(df_cols_process[df_cols_process['data types'] == 'nominal']['column']) \n",
    "column_ordinal = list(df_cols_process[df_cols_process['data types'] == 'ordinal']['column']) # no need processing\n",
    "column_binary = list(df_cols_process[df_cols_process['data types'] == 'binary']['column'])\n",
    "column_time = list(df_cols_process[df_cols_process['data types'] == 'time']['column'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e348cf",
   "metadata": {},
   "source": [
    "## Data Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7953738b",
   "metadata": {},
   "source": [
    "### Drop useless data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ffc9cf6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:47.020830Z",
     "start_time": "2023-01-15T14:14:47.017005Z"
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7bf936e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:47.217467Z",
     "start_time": "2023-01-15T14:14:47.205422Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_temp = train_df.drop('Id',axis = 1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c2cdf51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:47.405448Z",
     "start_time": "2023-01-15T14:14:47.392461Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_nominal = train_df_temp[column_nominal].copy()\n",
    "train_df_interval = train_df_temp[column_interval].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e8cee6",
   "metadata": {},
   "source": [
    "### Data Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed79fa8",
   "metadata": {},
   "source": [
    "#### Nominal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3913552",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:48.021606Z",
     "start_time": "2023-01-15T14:14:47.971314Z"
    }
   },
   "outputs": [],
   "source": [
    "# build an array for removing nominal columns that have missinv value more than 30%.\n",
    "col_major_missing = np.array(train_df_nominal.columns[train_df_nominal.isnull().sum()/train_df_nominal.shape[0] > 0.30])\n",
    "\n",
    "# drop it\n",
    "train_df_nominal = train_df_nominal.drop(col_major_missing, axis=1)\n",
    "\n",
    "# assign mode to a variable \"nominal mode\".\n",
    "nominal_mode = train_df_nominal.mode().iloc[0]\n",
    "\n",
    "# simple null value imputation: Mode\n",
    "train_df_nominal = train_df_nominal.fillna(nominal_mode)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afe2619",
   "metadata": {},
   "source": [
    "#### Interval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3421690d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:48.375985Z",
     "start_time": "2023-01-15T14:14:48.369264Z"
    }
   },
   "outputs": [],
   "source": [
    "# simple null value imputation: interval to 0\n",
    "train_df_interval = train_df_interval.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b4bc0f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:48.567611Z",
     "start_time": "2023-01-15T14:14:48.554252Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_temp = train_df_temp.drop(column_interval, axis=1)\n",
    "train_df_temp = pd.concat([train_df_temp, train_df_interval], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39116379",
   "metadata": {},
   "source": [
    "### Nominal data to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ac8dac4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:48.965538Z",
     "start_time": "2023-01-15T14:14:48.951762Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_nominal['MSSubClass'] = train_df_nominal['MSSubClass'].astype('string')\n",
    "train_df_nominal['MSSubClass'] = train_df_nominal['MSSubClass'].apply(lambda x: 'MSSC_'+x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ad351da",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:49.212102Z",
     "start_time": "2023-01-15T14:14:49.141831Z"
    }
   },
   "outputs": [],
   "source": [
    "# from 43 to 281 columns\n",
    "train_df_nominal = pd.get_dummies(train_df_nominal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d5dbea8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:49.348371Z",
     "start_time": "2023-01-15T14:14:49.335292Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_temp = train_df_temp.drop(column_nominal, axis=1)\n",
    "train_df_temp = pd.concat([train_df_temp, train_df_nominal], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a33a383a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:20:14.820500Z",
     "start_time": "2023-01-15T14:20:14.806382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Norm\n",
       "1       Norm\n",
       "2       Norm\n",
       "3       Norm\n",
       "4       Norm\n",
       "        ... \n",
       "1455    Norm\n",
       "1456    Norm\n",
       "1457    Norm\n",
       "1458    Norm\n",
       "1459    Norm\n",
       "Name: Condition2, Length: 1460, dtype: object"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['Condition2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "434fb92d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:19:55.264478Z",
     "start_time": "2023-01-15T14:19:55.244817Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1455    0\n",
       "1456    0\n",
       "1457    0\n",
       "1458    0\n",
       "1459    0\n",
       "Name: Condition2_RRAe, Length: 1460, dtype: uint8"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df_temp['Condition2_RRAe']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b68c34f",
   "metadata": {},
   "source": [
    "### Change the value of binary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f9e9ba3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:49.751591Z",
     "start_time": "2023-01-15T14:14:49.740126Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df_temp['CentralAir'] = train_df_temp[column_binary]['CentralAir'].apply(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af028b48",
   "metadata": {},
   "source": [
    "### Change the value of time data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f66b0c53",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:50.176682Z",
     "start_time": "2023-01-15T14:14:50.153667Z"
    }
   },
   "outputs": [],
   "source": [
    "# unique approach on how to process the time data\n",
    "train_df_temp['YearRemodAdd'] = train_df_temp[column_time]['YearRemodAdd'] - train_df_temp[column_time]['YearBuilt']\n",
    "train_df_temp['YrSold'] = train_df_temp[column_time]['YrSold'] - train_df_temp[column_time]['YearBuilt']\n",
    "\n",
    "train_df_temp_yrbuilt_min = train_df_temp[column_time]['YearBuilt'].min()\n",
    "train_df_temp['YearBuilt'] = train_df_temp[column_time]['YearBuilt'].apply(lambda x: x - train_df_temp_yrbuilt_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07a92fc2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:50.389487Z",
     "start_time": "2023-01-15T14:14:50.356300Z"
    }
   },
   "outputs": [],
   "source": [
    "# turn YrSold compare to Yr Built.\n",
    "train_df_temp['MoSold'] = train_df_temp['MoSold'].apply(lambda x: 'sold_'+calendar.month_name[x])\n",
    "train_df_temp_dum_months = pd.get_dummies(train_df_temp['MoSold'])\n",
    "train_df_temp = train_df_temp.drop(['MoSold'], axis=1)\n",
    "\n",
    "train_df_temp = pd.concat([train_df_temp,train_df_temp_dum_months], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd558d1",
   "metadata": {},
   "source": [
    "## Define Dependent and Response Data of Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "383cfa10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:50.777585Z",
     "start_time": "2023-01-15T14:14:50.766421Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train = train_df_temp.drop('SalePrice', axis=1)\n",
    "Y_train = train_df_temp['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bcb020a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d7887e",
   "metadata": {},
   "source": [
    "## Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded0479d",
   "metadata": {},
   "source": [
    "### Z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e21a22f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:52.886735Z",
     "start_time": "2023-01-15T14:14:52.200310Z"
    }
   },
   "outputs": [],
   "source": [
    "# Zscore using SKLearn\n",
    "\n",
    "from sklearn.preprocessing import scale\n",
    "# scale(X_orig, axis=0, with_mean=True, with_std=True, copy=True)\n",
    "\n",
    "def zscore_normalize_features(X, mu = False, sigma = False):\n",
    "    \"\"\"\n",
    "    computes  X, zcore normalized by column\n",
    "    \n",
    "    Args:\n",
    "      X (ndarray (m,n))     : input data, m examples, n features\n",
    "      \n",
    "    Returns:\n",
    "      X_norm (ndarray (m,n)): input normalized by column\n",
    "      mu (ndarray (n,))     : mean of each feature\n",
    "      sigma (ndarray (n,))  : standard deviation of each feature\n",
    "    \"\"\"\n",
    "    \n",
    "    if mu is False and sigma is False:\n",
    "        # find the mean of each column/feature\n",
    "        mu     = np.mean(X, axis=0)                 # mu will have shape (n,)\n",
    "        # find the standard deviation of each column/feature\n",
    "        sigma  = np.std(X, axis=0)                  # sigma will have shape (n,)\n",
    "        # element-wise, subtract mu for that column from each example, divide by std for that column\n",
    "        \n",
    "    X_norm = (X - mu) / sigma      \n",
    "\n",
    "    return (X_norm, mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "97c72e6c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:52.897767Z",
     "start_time": "2023-01-15T14:14:52.887897Z"
    }
   },
   "outputs": [],
   "source": [
    "# using SKLearn\n",
    "# X_norm = scale(X_train, with_mean = True, with_std = True, copy = True)\n",
    "X_train_scale, mu, sigma = zscore_normalize_features(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc715f7",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44460557",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:53.574785Z",
     "start_time": "2023-01-15T14:14:53.470627Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a19fdfad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:14:53.667378Z",
     "start_time": "2023-01-15T14:14:53.664710Z"
    }
   },
   "outputs": [],
   "source": [
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "536a42ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:20.782360Z",
     "start_time": "2023-01-15T14:15:20.769436Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_arr = np.array(X_train_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "74301350",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:24.299727Z",
     "start_time": "2023-01-15T14:15:24.167244Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.fit(X_train_arr, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5cfb669",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:25.068094Z",
     "start_time": "2023-01-15T14:15:25.062970Z"
    }
   },
   "outputs": [],
   "source": [
    "b = linear_model.intercept_\n",
    "w = linear_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a167475",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:31.257854Z",
     "start_time": "2023-01-15T14:15:31.242515Z"
    }
   },
   "outputs": [],
   "source": [
    "Y_train_pred = linear_model.predict(X_train_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808cd72e",
   "metadata": {},
   "source": [
    "## Root Mean Squared Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02f97d5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:34.876952Z",
     "start_time": "2023-01-15T14:15:34.870258Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac1fc551",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:35.688721Z",
     "start_time": "2023-01-15T14:15:35.679249Z"
    }
   },
   "outputs": [],
   "source": [
    "train_eval_metrics = math.sqrt(mean_squared_error(Y_train_pred, Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70a4ec46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:36.066360Z",
     "start_time": "2023-01-15T14:15:36.057857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20949.493465736316"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_eval_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7745a5",
   "metadata": {},
   "source": [
    "## Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57010251",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:37.517684Z",
     "start_time": "2023-01-15T14:15:37.479394Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9f30af3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:37.753445Z",
     "start_time": "2023-01-15T14:15:37.667523Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is test dataset return only X...\n"
     ]
    }
   ],
   "source": [
    "X_test, y = X_preprocessing(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7d32a9f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:37.874409Z",
     "start_time": "2023-01-15T14:15:37.847555Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_scale, mu_test, sigma_test = zscore_normalize_features(X_test, mu, sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ae48c1",
   "metadata": {},
   "source": [
    "## Adjust the column of train and test datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21b508f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:15:53.799821Z",
     "start_time": "2023-01-15T14:15:53.784442Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_scale_final, X_test_scale_final = X_train_scale.align(X_test_scale, join = 'left', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "45b5e1af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:21:19.935581Z",
     "start_time": "2023-01-15T14:21:19.925413Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test_scale_final = X_test_scale_final.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "502935a2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-01-15T14:21:45.869694Z",
     "start_time": "2023-01-15T14:21:45.858219Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_scale_final.columns[X_test_scale_final.isna().sum() != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62345e53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040419d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a0cab3e",
   "metadata": {},
   "source": [
    "# Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6becf47",
   "metadata": {},
   "source": [
    "https://medium.com/analytics-vidhya/ways-to-handle-categorical-column-missing-data-its-implementations-15dc4a56893#:~:text=Step%201%3A%20Find%20which%20category,and%20keep%20newly%20imputed%20columns.&text=Advantage%3A%20Simple%20and%20easy%20to%20implement%20for%20categorical%20variables%2Fcolumns.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
